{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1650752684364,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"KlXz1oWAN43-"},"outputs":[],"source":["from torch import nn\n","import torch\n","from Models import LSTMClassifier\n","from utils import get_device, get_loaders, prediction_binary"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4541,"status":"ok","timestamp":1650752688901,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"htGyUOhKNM_1"},"outputs":[],"source":["train_loader, val_loader, test_loader = get_loaders()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650752690762,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"y1AKaJO_NM_2","outputId":"c7e3ce34-f129-4371-b4d5-31bcee4f1ee7"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda:0\n","LSTMClassifier(\n","  (rnn): LSTMCell(47, 256)\n","  (fc): Linear(in_features=256, out_features=1, bias=True)\n","  (activation): Sigmoid()\n",")\n"]}],"source":["device = get_device()\n","model = LSTMClassifier(47, 256, 1, device)\n","model.to(device)\n","\n","print(device)\n","print(model)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1650752690763,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"GViCWS2MNM_5"},"outputs":[],"source":["opt = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n","loss_fn = nn.BCELoss().to(device)\n","best = 0\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267983,"status":"ok","timestamp":1650752958737,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"AfSaapJ-NM_5","outputId":"042b07a3-807f-4bd9-b502-dfad4e6e64d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch : 0.0 Train Loss 0.4450 Val Loss 0.3633 Val AUROC 0.6865\n","Epoch : 1.0 Train Loss 0.3749 Val Loss 0.3505 Val AUROC 0.7374\n","Epoch : 2.0 Train Loss 0.3622 Val Loss 0.3433 Val AUROC 0.7489\n","Epoch : 3.0 Train Loss 0.3561 Val Loss 0.3402 Val AUROC 0.7562\n","Epoch : 4.0 Train Loss 0.3513 Val Loss 0.3370 Val AUROC 0.7585\n","Epoch : 5.0 Train Loss 0.3482 Val Loss 0.3363 Val AUROC 0.7643\n","Epoch : 6.0 Train Loss 0.3440 Val Loss 0.3358 Val AUROC 0.7642\n","Epoch : 7.0 Train Loss 0.3420 Val Loss 0.3345 Val AUROC 0.7642\n","Epoch : 8.0 Train Loss 0.3402 Val Loss 0.3348 Val AUROC 0.7662\n","Epoch : 9.0 Train Loss 0.3374 Val Loss 0.3326 Val AUROC 0.7701\n","Epoch : 10.0 Train Loss 0.3359 Val Loss 0.3303 Val AUROC 0.7758\n","Epoch : 11.0 Train Loss 0.3329 Val Loss 0.3314 Val AUROC 0.7749\n","Epoch : 12.0 Train Loss 0.3297 Val Loss 0.3278 Val AUROC 0.7754\n","Epoch : 13.0 Train Loss 0.3282 Val Loss 0.3256 Val AUROC 0.7820\n","Epoch : 14.0 Train Loss 0.3252 Val Loss 0.3282 Val AUROC 0.7772\n","Epoch : 15.0 Train Loss 0.3230 Val Loss 0.3253 Val AUROC 0.7827\n","Epoch : 16.0 Train Loss 0.3205 Val Loss 0.3269 Val AUROC 0.7828\n","Epoch : 17.0 Train Loss 0.3190 Val Loss 0.3265 Val AUROC 0.7845\n","Epoch : 18.0 Train Loss 0.3170 Val Loss 0.3197 Val AUROC 0.7942\n","Epoch : 19.0 Train Loss 0.3133 Val Loss 0.3211 Val AUROC 0.7937\n","Epoch : 20.0 Train Loss 0.3122 Val Loss 0.3183 Val AUROC 0.7971\n","Epoch : 21.0 Train Loss 0.3094 Val Loss 0.3166 Val AUROC 0.7990\n","Epoch : 22.0 Train Loss 0.3085 Val Loss 0.3166 Val AUROC 0.7974\n","Epoch : 23.0 Train Loss 0.3069 Val Loss 0.3191 Val AUROC 0.7963\n","Epoch : 24.0 Train Loss 0.3049 Val Loss 0.3169 Val AUROC 0.7976\n","Epoch : 25.0 Train Loss 0.3024 Val Loss 0.3168 Val AUROC 0.8003\n","Epoch : 26.0 Train Loss 0.2997 Val Loss 0.3143 Val AUROC 0.8026\n","Epoch : 27.0 Train Loss 0.2978 Val Loss 0.3122 Val AUROC 0.8074\n","Epoch : 28.0 Train Loss 0.2964 Val Loss 0.3109 Val AUROC 0.8122\n","Epoch : 29.0 Train Loss 0.2934 Val Loss 0.3086 Val AUROC 0.8142\n","Epoch : 30.0 Train Loss 0.2908 Val Loss 0.3116 Val AUROC 0.8095\n","Epoch : 31.0 Train Loss 0.2889 Val Loss 0.3098 Val AUROC 0.8147\n","Epoch : 32.0 Train Loss 0.2866 Val Loss 0.3100 Val AUROC 0.8115\n","Epoch : 33.0 Train Loss 0.2843 Val Loss 0.3072 Val AUROC 0.8170\n","Epoch : 34.0 Train Loss 0.2826 Val Loss 0.3076 Val AUROC 0.8157\n","Epoch : 35.0 Train Loss 0.2791 Val Loss 0.3058 Val AUROC 0.8203\n","Epoch : 36.0 Train Loss 0.2769 Val Loss 0.3093 Val AUROC 0.8120\n","Epoch : 37.0 Train Loss 0.2744 Val Loss 0.3084 Val AUROC 0.8168\n","Epoch : 38.0 Train Loss 0.2753 Val Loss 0.3079 Val AUROC 0.8161\n","Epoch : 39.0 Train Loss 0.2718 Val Loss 0.3077 Val AUROC 0.8129\n","Epoch : 40.0 Train Loss 0.2692 Val Loss 0.3041 Val AUROC 0.8199\n","Epoch : 41.0 Train Loss 0.2687 Val Loss 0.3053 Val AUROC 0.8187\n","Epoch : 42.0 Train Loss 0.2655 Val Loss 0.3008 Val AUROC 0.8247\n","Epoch : 43.0 Train Loss 0.2631 Val Loss 0.3070 Val AUROC 0.8224\n","Epoch : 44.0 Train Loss 0.2631 Val Loss 0.2980 Val AUROC 0.8291\n","Epoch : 45.0 Train Loss 0.2574 Val Loss 0.3010 Val AUROC 0.8274\n","Epoch : 46.0 Train Loss 0.2571 Val Loss 0.2991 Val AUROC 0.8281\n","Epoch : 47.0 Train Loss 0.2566 Val Loss 0.3019 Val AUROC 0.8243\n","Epoch : 48.0 Train Loss 0.2540 Val Loss 0.3043 Val AUROC 0.8235\n","Epoch : 49.0 Train Loss 0.2513 Val Loss 0.3013 Val AUROC 0.8257\n","Epoch : 50.0 Train Loss 0.2492 Val Loss 0.2954 Val AUROC 0.8349\n","Epoch : 51.0 Train Loss 0.2475 Val Loss 0.3005 Val AUROC 0.8256\n","Epoch : 52.0 Train Loss 0.2460 Val Loss 0.3005 Val AUROC 0.8276\n","Epoch : 53.0 Train Loss 0.2436 Val Loss 0.2936 Val AUROC 0.8366\n","Epoch : 54.0 Train Loss 0.2428 Val Loss 0.2975 Val AUROC 0.8312\n","Epoch : 55.0 Train Loss 0.2395 Val Loss 0.2935 Val AUROC 0.8360\n","Epoch : 56.0 Train Loss 0.2416 Val Loss 0.2963 Val AUROC 0.8307\n","Epoch : 57.0 Train Loss 0.2342 Val Loss 0.2939 Val AUROC 0.8338\n","Epoch : 58.0 Train Loss 0.2321 Val Loss 0.2967 Val AUROC 0.8342\n","Epoch : 59.0 Train Loss 0.2308 Val Loss 0.3005 Val AUROC 0.8312\n","Epoch : 60.0 Train Loss 0.2282 Val Loss 0.2962 Val AUROC 0.8321\n","Epoch : 61.0 Train Loss 0.2275 Val Loss 0.2952 Val AUROC 0.8352\n","Epoch : 62.0 Train Loss 0.2272 Val Loss 0.2959 Val AUROC 0.8326\n","Epoch : 63.0 Train Loss 0.2241 Val Loss 0.2946 Val AUROC 0.8369\n","Epoch : 64.0 Train Loss 0.2221 Val Loss 0.2977 Val AUROC 0.8295\n","Epoch : 65.0 Train Loss 0.2202 Val Loss 0.2967 Val AUROC 0.8353\n","Epoch : 66.0 Train Loss 0.2208 Val Loss 0.2957 Val AUROC 0.8329\n","Epoch : 67.0 Train Loss 0.2174 Val Loss 0.2946 Val AUROC 0.8349\n","Epoch : 68.0 Train Loss 0.2146 Val Loss 0.2937 Val AUROC 0.8352\n","Epoch : 69.0 Train Loss 0.2124 Val Loss 0.2980 Val AUROC 0.8355\n","Epoch : 70.0 Train Loss 0.2100 Val Loss 0.3014 Val AUROC 0.8348\n","Epoch : 71.0 Train Loss 0.2085 Val Loss 0.2976 Val AUROC 0.8372\n","Epoch : 72.0 Train Loss 0.2060 Val Loss 0.3024 Val AUROC 0.8340\n","Epoch : 73.0 Train Loss 0.2045 Val Loss 0.2960 Val AUROC 0.8355\n","Epoch : 74.0 Train Loss 0.2017 Val Loss 0.2997 Val AUROC 0.8311\n"]}],"source":["TL = []\n","VL = []\n","VA = []\n","\n","for epoch in range(100):\n","    train_loss = 0\n","    for i, data in enumerate(train_loader):\n","\n","        model.train()\n","        opt.zero_grad()\n","\n","        inputs, label = data\n","        inputs = inputs.to(torch.float32).to(device)\n","        label = label.to(torch.float32).to(device)\n","\n","        pred = model(inputs)\n","        loss = loss_fn(pred[:, 0], label)\n","\n","        loss.backward()\n","        # torch.nn.utils.clip_grad_norm_(model.parameters(), 25)\n","        opt.step()\n","        train_loss += loss.detach().cpu()\n","\n","    val_loss, auc = prediction_binary(model, val_loader, loss_fn, device)\n","\n","    if auc > best:\n","        best = auc\n","        torch.save(model, './ihm_model')\n","\n","    train_loss /= len(train_loader)\n","\n","    print(f'Epoch: {epoch:.1f} || Train Loss: {train_loss:.4f}  Val Loss: {val_loss:.4f}  Val AUROC: {auc:.4f}')\n","    TL.append(train_loss)\n","    VL.append(val_loss)\n","    VA.append(auc)\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1650752959020,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"n8-3p61QNM_6","outputId":"bc1ed3a8-2302-4eb3-9b98-276268290508"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.8347456131625979\n"]}],"source":["\n","model = torch.load('./ihm_model')\n","loss, auc = prediction_binary(model, test_loader, loss_fn, device)\n","print(auc)\n"]}],"metadata":{"colab":{"name":"single_task.ipynb","provenance":[]},"interpreter":{"hash":"bb310a0600e1d400a6c8f46877b446ed3cb085597027e5897a298d5bf4cd6fca"},"kernelspec":{"display_name":"Python 3.9.12 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
