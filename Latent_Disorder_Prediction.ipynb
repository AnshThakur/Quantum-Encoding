{"cells":[{"cell_type":"markdown","metadata":{},"source":["This demo shows how to perform latent patient disorder or phenotype prediction from trained MIMIC-III models."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","from torch import nn\n","import torch\n","from utils.vit import TransformerEncoder\n","from utils.data_loaders import *\n","from utils.utils import *\n","from easydict import EasyDict as edict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4541,"status":"ok","timestamp":1650752688901,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"htGyUOhKNM_1"},"outputs":[],"source":["train_loader,val_loader,test_loader=get_loaders_pheno()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## load a stored model, could be LSTM, TF or TCN\n","device=get_device()\n","print(device)\n","model=torch.load('./RNN')\n","model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["loss_fn = nn.BCELoss().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","Train=[]\n","Train_Labels=[]\n","\n","for i,data in tqdm(enumerate(train_loader)):\n","    \n","    model.eval()\n","    inputs,label=data\n","    inputs=inputs.to(torch.float32).to(device)\n","    label=label.to(torch.float32).to(device)\n"," \n","    e=model.emb(inputs)\n","    Train.append(e)\n","    Train_Labels.append(label)\n","\n","Train=torch.vstack(Train)\n","Train_Labels=torch.vstack(Train_Labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","\n","Val=[]\n","Val_Labels=[]\n","\n","for i,data in tqdm(enumerate(val_loader)):\n","\n","    model.eval()\n","    inputs,label=data\n","    inputs=inputs.to(torch.float32).to(device)\n","    label=label.to(torch.float32).to(device)\n"," \n","    e=model.emb(inputs)\n","    Val.append(e)\n","    Val_Labels.append(label)\n","\n","Val=torch.vstack(Val)\n","Val_Labels=torch.vstack(Val_Labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","\n","Test=[]\n","Test_Labels=[]\n","\n","for i,data in tqdm(enumerate(test_loader)):\n","\n","    model.eval()\n","    inputs,label=data\n","    inputs=inputs.to(torch.float32).to(device)\n","    label=label.to(torch.float32).to(device)\n"," \n","    e=model.emb(inputs)\n","    Test.append(e)\n","    Test_Labels.append(label)\n","\n","Test=torch.vstack(Test)\n","Test_Labels=torch.vstack(Test_Labels)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from utils.Recurrent_Models import Emb_pheno\n","pheno_model=Emb_pheno(256,25,device)\n","pheno_model.to(device)\n","print(pheno_model)\n","opt = torch.optim.Adam(params=pheno_model.parameters(),lr=0.001)\n","loss_fn = nn.BCELoss().to(device)\n","best=0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch.utils.data import TensorDataset, DataLoader\n","train_dataset= TensorDataset(torch.tensor(Train),torch.tensor(Train_Labels))\n","train_loader = DataLoader(train_dataset, batch_size=64)\n","\n","val_dataset= TensorDataset(torch.tensor(Val),torch.tensor(Val_Labels))\n","val_loader = DataLoader(val_dataset, batch_size=64)\n","\n","test_dataset= TensorDataset(torch.tensor(Test),torch.tensor(Test_Labels))\n","test_loader = DataLoader(test_dataset, batch_size=64)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sklearn.metrics\n","\n","def prediction(model,loader,loss_fn,device):\n","    P=[]\n","    L=[]\n","    model.eval()\n","    val_loss=0\n","\n","    for i,batch in enumerate(loader):\n","        \n","        data,labels=batch\n","        data=data.to(torch.float32).to(device)\n","        labels=labels.to(torch.float32).to(device)\n","\n","        pred=model(data)\n","        loss=loss_fn(pred,labels)\n","        val_loss=val_loss+loss.item()\n","        P += list(pred.detach().cpu().numpy())\n","        L += list(labels.detach().cpu().numpy())\n","\n","    val_loss=val_loss/len(loader)\n","    L=np.vstack(L)\n","    P=np.vstack(P)\n","    roc_test=sklearn.metrics.roc_auc_score(L,P,average='macro')\n","    return val_loss,roc_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267983,"status":"ok","timestamp":1650752958737,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"AfSaapJ-NM_5","outputId":"042b07a3-807f-4bd9-b502-dfad4e6e64d5"},"outputs":[],"source":["from tqdm import tqdm\n","TL=[]\n","VL=[]\n","VA=[]\n","\n","for epoch in range(0,500):\n","    train_loss=0\n","    for i,data in enumerate(train_loader):\n","\n","\n","        model.train()\n","        opt.zero_grad()\n","      \n","\n","        inputs,label=data\n","        inputs=inputs.to(torch.float32).to(device)\n","        label=label.to(torch.float32).to(device)\n"," \n","        pred=pheno_model(inputs)\n","        loss=loss_fn(pred,label)\n","\n","        loss.backward()\n"," \n","        opt.step()     \n","        train_loss=train_loss+loss.detach().cpu()\n","         \n","      \n","    val_loss,auc=prediction(pheno_model,val_loader,loss_fn,device)\n","\n","    if auc>best:\n","       best=auc\n","       torch.save(model,'./pheno')\n","\n","    print('Epoch : {:.1f} Train Loss {:.4f} Val Loss {:.4f} Val AUROC {:.4f}'.format(epoch,train_loss/len(train_loader),val_loss,auc))  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1650752959020,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"n8-3p61QNM_6","outputId":"bc1ed3a8-2302-4eb3-9b98-276268290508"},"outputs":[],"source":["\n","model=torch.load('./pheno')\n","loss,auc=prediction(pheno_model,test_loader,loss_fn,device) \n","print(auc)"]}],"metadata":{"colab":{"name":"single_task.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"bb310a0600e1d400a6c8f46877b446ed3cb085597027e5897a298d5bf4cd6fca"}}},"nbformat":4,"nbformat_minor":0}
