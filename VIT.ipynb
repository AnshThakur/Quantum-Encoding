{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1704,"status":"ok","timestamp":1650752684364,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"KlXz1oWAN43-"},"outputs":[],"source":["import numpy as np\n","from torch import nn\n","import torch\n","from utils.vit import TransformerEncoder\n","from utils.data_loaders import *\n","from utils.utils import *\n","from easydict import EasyDict as edict"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4541,"status":"ok","timestamp":1650752688901,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"htGyUOhKNM_1"},"outputs":[],"source":["train_loader,val_loader,test_loader=get_loaders_IHM(sampler=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1650752690762,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"y1AKaJO_NM_2","outputId":"c7e3ce34-f129-4371-b4d5-31bcee4f1ee7"},"outputs":[],"source":["device=get_device()\n","print(device)\n","\n","cf = edict() \n","\n","cf.vit_args = {\n","        \"num_classes\": 1,\n","        \"dim\": 76,\n","        \"depth\": 1,\n","        \"use_class_token\": True,   # ViT are just transformers that use class token as video representations\n","        \"heads\":16,  # head number of transformer\n","        \"ff_dim\":16,  # MLP dimension of transformer's feedforward layer\n","        \"mlp_head_hidden_dim\":[128],   # the hidden layer dimensions of the MLP head\n","        \"dim_head\":256,  # head dimension of transformer's attention module\n","        \"pool\":\"cls\",  # \"cls\" or \"mean\"\n","        \"dropout\":0.5,  # dropout rate of transformer\n","        \"mlp_head_dropout\":0.5,   # dropout rate of the MLP head\n","        \"pe_method\":'origin',  # the Positional Embedding method\n","        \"pe_max_len\":48,  # the maximum sequence length for Positional Embedding\n","        \"activation\":\"gelu\",   # the activation method, can be \"gelu\" \"prelu\" or \"relu\"\n","    }\n","\n","model=TransformerEncoder(**cf.vit_args)\n","model.to(device)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1650752690763,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"GViCWS2MNM_5"},"outputs":[],"source":["opt = torch.optim.Adam(params=model.parameters(),lr=0.0001)\n","loss_fn = nn.BCELoss().to(device)\n","best=0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":267983,"status":"ok","timestamp":1650752958737,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"AfSaapJ-NM_5","outputId":"042b07a3-807f-4bd9-b502-dfad4e6e64d5"},"outputs":[],"source":["from tqdm import tqdm\n","TL=[]\n","VL=[]\n","VA=[]\n","\n","for epoch in range(0,50):\n","    train_loss=0\n","    for i,data in enumerate(train_loader):\n","\n","\n","        model.train()\n","        opt.zero_grad()\n","      \n","\n","        inputs,label=data\n","        inputs=inputs.to(torch.float32).to(device)\n","        label=label.to(torch.float32).to(device)\n"," \n","        pred=model(inputs)\n","        loss=loss_fn(pred[:,0],label)\n","\n","        loss.backward()\n"," \n","        opt.step()     \n","        train_loss=train_loss+loss.detach().cpu()\n","         \n","      \n","    val_loss,auc=prediction_binary(model,val_loader,loss_fn,device)\n","\n","    if auc>best:\n","       best=auc\n","       torch.save(model,'./VIT')\n","\n","    print('Epoch : {:.1f} Train Loss {:.4f} Val Loss {:.4f} Val AUROC {:.4f}'.format(epoch,train_loss/len(train_loader),val_loss,auc))  \n","    TL.append(train_loss/len(train_loader))\n","    VL.append(val_loss)\n","    VA.append(auc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":286,"status":"ok","timestamp":1650752959020,"user":{"displayName":"Anshul Thakur","userId":"11719449395424920327"},"user_tz":-60},"id":"n8-3p61QNM_6","outputId":"bc1ed3a8-2302-4eb3-9b98-276268290508"},"outputs":[],"source":["\n","model=torch.load('./VIT')\n","loss,auc=prediction_binary(model,test_loader,loss_fn,device) \n","print(auc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n","params = sum([np.prod(p.size()) for p in model_parameters])"]}],"metadata":{"colab":{"name":"single_task.ipynb","provenance":[]},"interpreter":{"hash":"bb310a0600e1d400a6c8f46877b446ed3cb085597027e5897a298d5bf4cd6fca"},"kernelspec":{"display_name":"Python 3.9.12 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
